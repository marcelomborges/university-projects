batch_size = 10
n_epochs   = 10
CNN(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv8): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=2048, out_features=512, bias=True)
  (fc2): Linear(in_features=512, out_features=2, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)
Epoch: 1 	Training Loss: 0.694809 	Validation Loss: 0.693065
Epoch: 2 	Training Loss: 0.693642 	Validation Loss: 0.693236
Epoch: 3 	Training Loss: 0.693320 	Validation Loss: 0.693184
Epoch: 4 	Training Loss: 0.693378 	Validation Loss: 0.693141
Epoch: 5 	Training Loss: 0.693404 	Validation Loss: 0.693251
Epoch: 6 	Training Loss: 0.693611 	Validation Loss: 0.693306
Epoch: 7 	Training Loss: 0.693321 	Validation Loss: 0.693224
Epoch: 8 	Training Loss: 0.693287 	Validation Loss: 0.693192
Epoch: 9 	Training Loss: 0.693301 	Validation Loss: 0.693142
Epoch: 10 	Training Loss: 0.693367 	Validation Loss: 0.693189
best_batch = 1
Accuracy   = 0.5

